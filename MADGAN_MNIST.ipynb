{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MADGAN_keras_MNIST_GPUoptimized.ipynb","provenance":[{"file_id":"1KdkvmOFD-MbB8XoNsUvY143nbWZiMXF_","timestamp":1632524713515},{"file_id":"1K7vx6pQ4bvQaHQpQIIb1aasPUzGok_ky","timestamp":1631562445382},{"file_id":"1hY2dSGFfGb9UEEUKU8sQYjeXb__kUFUD","timestamp":1629483313868}],"collapsed_sections":["HzKxAhSMBfBo","lLAblToISVhT","jcBSwiMhBY6s","5E683Gw4SPui","LA8ZWX0RBkIc","gq-5JHkdCWw0","9bGANAiQFCof","4oJJxQwlKH-D"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"HzKxAhSMBfBo"},"source":["# Hyper-parameters"]},{"cell_type":"code","metadata":{"id":"KG1kJCaTyILq","executionInfo":{"status":"ok","timestamp":1632608477861,"user_tz":-210,"elapsed":3,"user":{"displayName":"Alireza Daeijavad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09426646207156988252"}}},"source":["dir_name = \"MNIST_Model4\" #location to save the model in Google Drive"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"bPYGZFI8g-0C","executionInfo":{"status":"ok","timestamp":1632608477862,"user_tz":-210,"elapsed":3,"user":{"displayName":"Alireza Daeijavad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09426646207156988252"}}},"source":["n_Gen = 3 #number of generators\n","latent_dim = 256 #dimention of input noise\n","batch_size = 256 #number of batches\n","size_dataset = 60000 #size MNIST dataset\n","\n","steps_per_epoch = (size_dataset//batch_size)//n_Gen"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lLAblToISVhT"},"source":["# Adding Libraries"]},{"cell_type":"code","metadata":{"id":"kUzwSXEogl5B","executionInfo":{"status":"ok","timestamp":1632608481293,"user_tz":-210,"elapsed":3434,"user":{"displayName":"Alireza Daeijavad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09426646207156988252"}}},"source":["import matplotlib.pyplot as plt\n","from sklearn import mixture\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import (Input, Dense, Dropout, LeakyReLU, \n","                                     ReLU, Conv2D,Conv2DTranspose, Flatten,\n","                                     Reshape, BatchNormalization)\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import CategoricalCrossentropy\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras import Model\n","from google.colab import output\n","\n","import os\n","from IPython import display"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hf4eBNVlUImO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632608492738,"user_tz":-210,"elapsed":11447,"user":{"displayName":"Alireza Daeijavad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09426646207156988252"}},"outputId":"c536f1d1-4f41-4bdc-b173-e18a50d244ef"},"source":["# for saving GIF\n","!pip install pygifsicle\n","!sudo apt-get install gifsicle\n","import imageio\n","import glob\n","from pygifsicle import optimize\n","output.clear()\n","print(\"Import Done\")"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Import Done\n"]}]},{"cell_type":"markdown","metadata":{"id":"jcBSwiMhBY6s"},"source":["# To see if we have a GPU"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xCanhRwP_i9r","executionInfo":{"status":"ok","timestamp":1632602350152,"user_tz":-210,"elapsed":559,"user":{"displayName":"Alireza Daeijavad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09426646207156988252"}},"outputId":"6f115a21-b775-4c64-e9a6-fca0defd17cc"},"source":["print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n","\n","if tf.test.gpu_device_name() == '/device:GPU:0':\n","    print(\"Using a GPU\")\n","else:\n","    print(\"Using a CPU\")"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Num GPUs Available:  1\n","Using a GPU\n"]}]},{"cell_type":"markdown","metadata":{"id":"5E683Gw4SPui"},"source":["# Mount Google drive to save model and data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zzRNpAtj5Owg","executionInfo":{"status":"ok","timestamp":1632608530856,"user_tz":-210,"elapsed":38122,"user":{"displayName":"Alireza Daeijavad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09426646207156988252"}},"outputId":"ba5399cc-9e67-4c1b-91f5-042d027bd3c7"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","if os.path.exists(f'/content/drive/MyDrive/{dir_name}') == False:\n","    os.mkdir(f'/content/drive/MyDrive/{dir_name}')\n","if os.path.exists(f'/content/drive/MyDrive/{dir_name}/Pictures') == False:\n","    os.mkdir(f'/content/drive/MyDrive/{dir_name}/Pictures')"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"LA8ZWX0RBkIc"},"source":["# Producing Dataset"]},{"cell_type":"markdown","metadata":{"id":"49m6nYeg2wKe"},"source":["##### Loading MNIST and convert it to stacked-MNIST"]},{"cell_type":"code","metadata":{"id":"APG7_cXIsPJ_","executionInfo":{"status":"ok","timestamp":1632602350153,"user_tz":-210,"elapsed":3,"user":{"displayName":"Alireza Daeijavad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09426646207156988252"}}},"source":["def dataset1_func(random_state = None):\n","    (train_images, _), (_, _) = tf.keras.datasets.mnist.load_data()\n","\n","    train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n","    # train_images = tf.image.resize(train_images, [32,32])\n","    train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]\n","\n","    # Convert to stacked-mnist(rgb images)\n","    t1 = tf.random.shuffle(train_images, seed = 10)\n","    t2 = tf.random.shuffle(train_images, seed = 20)\n","    train_images = tf.concat([train_images, t1, t2], axis=-1)\n","    \n","    return train_images"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gq-5JHkdCWw0"},"source":["# Some Functions"]},{"cell_type":"markdown","metadata":{"id":"YG6jf2kZMMzR"},"source":["##### Ù”Noise Generator\n","\n"]},{"cell_type":"code","metadata":{"id":"eHjMJzyPWHFg","executionInfo":{"status":"ok","timestamp":1632602350624,"user_tz":-210,"elapsed":474,"user":{"displayName":"Alireza Daeijavad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09426646207156988252"}}},"source":["from tensorflow_probability import distributions as tfd\n","\n","# generate points in latent space as input for the generator\n","def generate_latent_points(latent_dim, batch_size, n_Gen):\n","    # Multivariate normal diagonal distribution\n","    mvn = tfd.MultivariateNormalDiag(\n","        loc=[0]*latent_dim,\n","        scale_diag=[1.0]*latent_dim)\n","\n","    noise = []\n","    for i in range(n_Gen):\n","        # Some samples from MVN\n","        x_input = mvn.sample(batch_size)\n","        noise.append(x_input)\n","    return noise"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9bGANAiQFCof"},"source":["##### Loss function for the generators based on the MAD_GAN paper"]},{"cell_type":"code","metadata":{"id":"My2Uno7bFEPJ","executionInfo":{"status":"ok","timestamp":1632602350624,"user_tz":-210,"elapsed":3,"user":{"displayName":"Alireza Daeijavad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09426646207156988252"}}},"source":["def Generators_loss_function(y_true, y_pred): \n","    logarithm = -tf.math.log(y_pred[:,-1] + 1e-15)\n","    return tf.reduce_mean(logarithm, axis=-1)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4oJJxQwlKH-D"},"source":["##### A callback which runs at end of each epoch to save and plot the results"]},{"cell_type":"code","metadata":{"id":"GKU1N6KsH9X8","executionInfo":{"status":"ok","timestamp":1632602350625,"user_tz":-210,"elapsed":4,"user":{"displayName":"Alireza Daeijavad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09426646207156988252"}}},"source":["class GANMonitor1(tf.keras.callbacks.Callback):\n","    def __init__(self, random_latent_vectors, data, plot_freq = 5, num_img = 3, latent_dim = 128, n_Gen = 6, dir_name = 'Model'):\n","        self.data = data[0:2]\n","        self.random_latent_vectors = random_latent_vectors\n","        self.plot_freq = plot_freq\n","        self.num_img = num_img\n","        self.latent_dim = latent_dim\n","        self.n_Gen = n_Gen\n","        self.dir_name = dir_name\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        if (epoch + 1) % self.plot_freq == 0:\n","            fig = plt.figure(figsize=(12, 6))\n","            fig.suptitle(f'Epoch {(epoch + 1):04}')\n","            for i in range(self.num_img):\n","                plt.subplot(4,8,7 + i)\n","                plt.title(f'Real {i+1}')\n","                plt.imshow((self.data[i, :, :, :] * 127.5 + 127.5)/255, aspect = 'equal')\n","                plt.axis('off')\n","                plt.subplot(4,8,15 + i)\n","                plt.imshow(self.data[i, :, :, 0] * 127.5 + 127.5, cmap = 'gray', aspect = 'equal', vmin=0, vmax=255)\n","                plt.axis('off')\n","                plt.subplot(4,8,23 + i)\n","                plt.imshow(self.data[i, :, :, 1] * 127.5 + 127.5, cmap = 'gray', aspect = 'equal', vmin=0, vmax=255)\n","                plt.axis('off')\n","                plt.subplot(4,8,31 + i)\n","                plt.imshow(self.data[i, :, :, 2] * 127.5 + 127.5, cmap = 'gray', aspect = 'equal', vmin=0, vmax=255)\n","                plt.axis('off')\n","\n","            for g in range(self.n_Gen):\n","                generated_samples = self.model.generators[g](self.random_latent_vectors[g])\n","                for i in range(self.num_img):\n","                    plt.subplot(4,8,g*2 + i + 1)\n","                    plt.title(f'Gen {g + 1}')\n","                    plt.imshow((generated_samples[i, :, :, :] * 127.5 + 127.5)/255, aspect = 'equal')\n","                    plt.axis('off')\n","                    plt.subplot(4,8,g*2 + i + 9)\n","                    plt.imshow(generated_samples[i, :, :, 0] * 127.5 + 127.5, cmap = 'gray', aspect = 'equal', vmin=0, vmax=255)\n","                    plt.axis('off')\n","                    plt.subplot(4,8,g*2 + i + 17)\n","                    plt.imshow(generated_samples[i, :, :, 1] * 127.5 + 127.5, cmap = 'gray', aspect = 'equal', vmin=0, vmax=255)\n","                    plt.axis('off')\n","                    plt.subplot(4,8,g*2 + i + 25)\n","                    plt.imshow(generated_samples[i, :, :, 2] * 127.5 + 127.5, cmap = 'gray', aspect = 'equal', vmin=0, vmax=255)\n","                    plt.axis('off')\n","\n","            plt.subplots_adjust(hspace = 0.05, wspace = 0.05)\n","            plt.savefig(f'/content/drive/MyDrive/{self.dir_name}/Pictures/image_at_epoch_{(epoch + 1):04}.png', dpi=200, format=\"png\")\n","\n","            # To show the plots in colab comment line below and uncomment the next line\n","            plt.close()\n","            # plt.show()"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u_mXp7LPHltf"},"source":["# Defining Discriminator Model"]},{"cell_type":"code","metadata":{"id":"t01kZc3TsTMl","executionInfo":{"status":"ok","timestamp":1632602350626,"user_tz":-210,"elapsed":4,"user":{"displayName":"Alireza Daeijavad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09426646207156988252"}}},"source":["# define the standalone discriminator model\n","def define_discriminator(n_Gen):\n","    inp = Input(shape=(28, 28, 3))\n","\n","    x = Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 3])(inp)\n","    x = LeakyReLU()(x)\n","    x = Dropout(0.3)(x)\n","\n","    x = Conv2D(128, (5, 5), strides=(2, 2), padding='same')(x)\n","    x = LeakyReLU()(x)\n","    x = Dropout(0.3)(x)\n","    \n","    x = Flatten()(x)\n","    out = Dense(n_Gen + 1, activation = 'softmax')(x)\n","\n","    model = Model(inp, out, name=\"Discriminator\")\n","    return model"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NQ960Kc_JLxW"},"source":["# Defining Generators Model"]},{"cell_type":"code","metadata":{"id":"gZgacXjViZGb","executionInfo":{"status":"ok","timestamp":1632602350627,"user_tz":-210,"elapsed":5,"user":{"displayName":"Alireza Daeijavad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09426646207156988252"}}},"source":["def define_generators(n_Gen, latent_dim):\n","    dens = Dense(7*7*256, use_bias=False, input_shape=(latent_dim,))\n","    batchnorm0 = BatchNormalization()\n","    rel0 = LeakyReLU()\n","    reshape0 = Reshape([7,7,latent_dim])\n","\n","    con2dt1 = Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)\n","    batchnorm1 = BatchNormalization()\n","    rel1 = LeakyReLU()\n","\n","    con2dt2 = Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n","    batchnorm2 = BatchNormalization()\n","    rel2 = LeakyReLU()\n","\n","    models = []\n","    for g in range(n_Gen):\n","        input = Input(shape=(latent_dim,), dtype = tf.float64, name=f\"input_{g}\")\n","        x = dens(input)\n","        x = batchnorm0(x)\n","        x = rel0(x)\n","        x = reshape0(x)\n","\n","        x = con2dt1(x)\n","        x = batchnorm1(x)\n","        x = rel1(x)\n","        \n","        x = con2dt2(x)\n","        x = batchnorm2(x)\n","        x = rel2(x)\n","        \n","        x = Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')(x)\n","        \n","        models.append(Model(input, x, name = f\"generator{g}\"))\n","    return models"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hm2I8u4cK29o"},"source":["# Defining MADGAN Class for training via keras"]},{"cell_type":"code","metadata":{"id":"LyvfweJ4uoz4","executionInfo":{"status":"ok","timestamp":1632602350986,"user_tz":-210,"elapsed":364,"user":{"displayName":"Alireza Daeijavad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09426646207156988252"}}},"source":["class MADGAN(tf.keras.Model):\n","    def __init__(self, discriminator, generators, latent_dim, n_Gen):\n","        super(MADGAN, self).__init__()\n","        self.discriminator = discriminator\n","        self.generators = generators\n","        self.latent_dim = latent_dim\n","        self.n_Gen = n_Gen\n","\n","    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n","        super(MADGAN, self).compile()\n","        self.d_optimizer = d_optimizer\n","        self.g_optimizer = g_optimizer\n","        self.d_loss_fn = d_loss_fn\n","        self.g_loss_fn = g_loss_fn\n","\n","    def train_step(self, data):\n","        X = data\n","        \n","        # Get the batch size\n","        batch_size = tf.shape(X)[0]\n","        # Sample random points in the latent space\n","        random_latent_vectors = generate_latent_points(self.latent_dim, batch_size//self.n_Gen, self.n_Gen)\n","        # Decode them to fake generator output\n","        x_generator = []\n","        for g in range(self.n_Gen):\n","            x_generator.append(self.generators[g](random_latent_vectors[g]))\n","        \n","        # Combine them with real samples\n","        combined_samples = tf.concat([x_generator[g] for g in range(self.n_Gen)] + \n","                                     [X], \n","                                     axis=0\n","                                     )\n","        # Assemble labels discriminating real from fake samples\n","        labels = tf.concat([tf.one_hot(g * tf.ones(batch_size//self.n_Gen, dtype=tf.int32), self.n_Gen + 1) for g in range(self.n_Gen)] + \n","                    [tf.one_hot(self.n_Gen * tf.ones(batch_size, dtype=tf.int32), self.n_Gen + 1)], \n","                    axis=0\n","                    )\n","\n","        # Add random noise to the labels - important trick!\n","        labels += 0.05 * tf.random.uniform(shape = tf.shape(labels), minval = -1, maxval = 1)\n","\n","        #######################\n","        # Train Discriminator #\n","        #######################\n","        \n","        # make weights in the discriminator trainable\n","        with tf.GradientTape() as tape:\n","            # Discriminator forward pass\n","            predictions = self.discriminator(combined_samples)\n","\n","            # Compute the loss value\n","            # (the loss function is configured in `compile()`)\n","            d_loss = self.d_loss_fn(labels, predictions)\n","\n","        # Compute gradients\n","        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n","\n","\n","        # Update weights\n","        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n","\n","        #######################\n","        #   Train Generator   #\n","        #######################\n","\n","        # Assemble labels that say \"all real samples\"\n","        misleading_labels =  tf.one_hot(self.n_Gen * tf.ones(batch_size//self.n_Gen, dtype=tf.int32), self.n_Gen + 1)\n","\n","        # (note that we should *not* update the weights of the discriminator)!\n","        g_loss_list = []\n","        fake_image = []\n","        for g in range(self.n_Gen):\n","            with tf.GradientTape() as tape:\n","                # Generator[g] and discriminator forward pass\n","                predictions = self.discriminator(self.generators[g](random_latent_vectors[g]))\n","                \n","                # Compute the loss value\n","                # (the loss function is configured in `compile()`)\n","                g_loss = self.g_loss_fn(misleading_labels, predictions)\n","\n","            # Compute gradients\n","            grads = tape.gradient(g_loss, self.generators[g].trainable_weights)\n","            # Update weights\n","            self.g_optimizer[g].apply_gradients(zip(grads, self.generators[g].trainable_weights))\n","            g_loss_list.append(g_loss)\n","\n","        mydict = {f\"g_loss{g}\": g_loss_list[g] for g in range(self.n_Gen)}\n","        mydict.update({\"d_loss\": d_loss})\n","        return mydict"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-tmPpH6dLBAV"},"source":["# Creating Model and training it"]},{"cell_type":"code","metadata":{"id":"SunFHoSGCCNg","colab":{"base_uri":"https://localhost:8080/"},"outputId":"521e4b24-a9bd-4307-944d-db51e0df6ee4"},"source":["# Loading data\n","data = dataset1_func()\n","# Changing numpy dataset to tf.DATASET type and Shuffling dataset for training\n","dataset = tf.data.Dataset.from_tensor_slices(data) \n","dataset = dataset.repeat().shuffle(10 * size_dataset, reshuffle_each_iteration=True).batch(n_Gen * batch_size, drop_remainder=True)\n","\n","# Creating Discriminator and Generator\n","discriminator = define_discriminator(n_Gen)\n","discriminator.summary()\n","generators = define_generators(n_Gen, latent_dim)\n","generators[0].summary()\n","\n","# creating MADGAN\n","madgan = MADGAN(discriminator = discriminator, generators = generators, \n","                latent_dim = latent_dim, n_Gen = n_Gen)\n","\n","madgan.compile(\n","    d_optimizer = Adam(learning_rate=2e-4, beta_1=0.5),\n","    g_optimizer = [Adam(learning_rate=1e-4, beta_1=0.5) for g in range(n_Gen)],\n","    d_loss_fn = CategoricalCrossentropy(),\n","    g_loss_fn = Generators_loss_function\n",")\n","\n","checkpoint_filepath = f'/content/drive/MyDrive/{dir_name}/checkpoint'\n","random_latent_vectors = generate_latent_points(latent_dim = latent_dim, batch_size = 2, n_Gen = n_Gen)\n","\n","my_callbacks = [\n","    # This callback is for ploting generators' output every epoch\n","    GANMonitor1(random_latent_vectors, data = data, plot_freq = 1, num_img = 2, latent_dim = latent_dim, n_Gen = n_Gen, dir_name = dir_name),\n","    # This callback is for Saving the model every 15 epochs\n","    tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_filepath , save_freq = 20, save_weights_only = True),\n","]\n","\n","# # Loading previous saved model for resume training\n","# if os.path.exists(checkpoint_filepath):\n","#     madgan.load_weights(checkpoint_filepath)\n","\n","# train the model\n","madgan.fit(dataset, epochs = 200, steps_per_epoch = steps_per_epoch, verbose = 1, callbacks = my_callbacks)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"Discriminator\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 28, 28, 3)]       0         \n","_________________________________________________________________\n","conv2d (Conv2D)              (None, 14, 14, 64)        4864      \n","_________________________________________________________________\n","leaky_re_lu (LeakyReLU)      (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 7, 7, 128)         204928    \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 6272)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 4)                 25092     \n","=================================================================\n","Total params: 234,884\n","Trainable params: 234,884\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"generator0\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_0 (InputLayer)         [(None, 256)]             0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 12544)             3211264   \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 12544)             50176     \n","_________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)    (None, 12544)             0         \n","_________________________________________________________________\n","reshape (Reshape)            (None, 7, 7, 256)         0         \n","_________________________________________________________________\n","conv2d_transpose (Conv2DTran (None, 7, 7, 128)         819200    \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 7, 7, 128)         512       \n","_________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)    (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","conv2d_transpose_1 (Conv2DTr (None, 14, 14, 64)        204800    \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n","_________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)    (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","conv2d_transpose_2 (Conv2DTr (None, 28, 28, 3)         4800      \n","=================================================================\n","Total params: 4,291,008\n","Trainable params: 4,265,536\n","Non-trainable params: 25,472\n","_________________________________________________________________\n","Epoch 1/200\n"," 6/78 [=>............................] - ETA: 28s - g_loss0: 1.2926 - g_loss1: 1.2800 - g_loss2: 1.2428 - d_loss: 1.0856WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0838s vs `on_train_batch_end` time: 0.2792s). Check your callbacks.\n","78/78 [==============================] - 38s 423ms/step - g_loss0: 1.4107 - g_loss1: 1.3386 - g_loss2: 1.4140 - d_loss: 0.7586\n","Epoch 2/200\n","78/78 [==============================] - 33s 424ms/step - g_loss0: 1.1882 - g_loss1: 1.0963 - g_loss2: 0.9725 - d_loss: 1.0041\n","Epoch 3/200\n","78/78 [==============================] - 33s 427ms/step - g_loss0: 1.4693 - g_loss1: 1.4876 - g_loss2: 1.3202 - d_loss: 0.9398\n","Epoch 4/200\n","78/78 [==============================] - 34s 435ms/step - g_loss0: 2.1914 - g_loss1: 1.7928 - g_loss2: 1.9206 - d_loss: 0.8223\n","Epoch 5/200\n","78/78 [==============================] - 33s 430ms/step - g_loss0: 2.8792 - g_loss1: 2.2408 - g_loss2: 2.0782 - d_loss: 0.5858\n","Epoch 6/200\n","78/78 [==============================] - 34s 430ms/step - g_loss0: 2.8452 - g_loss1: 2.2344 - g_loss2: 2.0869 - d_loss: 0.6189\n","Epoch 7/200\n","78/78 [==============================] - 33s 428ms/step - g_loss0: 1.4185 - g_loss1: 1.1243 - g_loss2: 1.4649 - d_loss: 0.7139\n","Epoch 8/200\n","78/78 [==============================] - 34s 437ms/step - g_loss0: 1.5985 - g_loss1: 1.7220 - g_loss2: 1.7851 - d_loss: 0.5325\n","Epoch 9/200\n","78/78 [==============================] - 34s 431ms/step - g_loss0: 1.5779 - g_loss1: 1.5433 - g_loss2: 1.5347 - d_loss: 0.6524\n","Epoch 10/200\n","78/78 [==============================] - 34s 435ms/step - g_loss0: 1.5076 - g_loss1: 1.3965 - g_loss2: 1.3130 - d_loss: 0.7282\n","Epoch 11/200\n","78/78 [==============================] - 33s 423ms/step - g_loss0: 1.1883 - g_loss1: 1.3735 - g_loss2: 1.3507 - d_loss: 0.7512\n","Epoch 12/200\n","78/78 [==============================] - 33s 429ms/step - g_loss0: 1.4100 - g_loss1: 1.2574 - g_loss2: 1.6001 - d_loss: 0.7784\n","Epoch 13/200\n","78/78 [==============================] - 33s 428ms/step - g_loss0: 1.2892 - g_loss1: 1.1576 - g_loss2: 1.2385 - d_loss: 0.7245\n","Epoch 14/200\n","78/78 [==============================] - 34s 433ms/step - g_loss0: 1.2715 - g_loss1: 1.3484 - g_loss2: 1.2597 - d_loss: 0.6637\n","Epoch 15/200\n","78/78 [==============================] - 34s 434ms/step - g_loss0: 1.5247 - g_loss1: 1.2930 - g_loss2: 1.5247 - d_loss: 0.7324\n","Epoch 16/200\n","78/78 [==============================] - 34s 431ms/step - g_loss0: 1.5453 - g_loss1: 1.2683 - g_loss2: 1.5615 - d_loss: 0.7778\n","Epoch 17/200\n","78/78 [==============================] - 34s 434ms/step - g_loss0: 1.3154 - g_loss1: 1.3821 - g_loss2: 1.2426 - d_loss: 0.7823\n","Epoch 18/200\n","78/78 [==============================] - 34s 431ms/step - g_loss0: 1.3691 - g_loss1: 1.4370 - g_loss2: 1.2802 - d_loss: 0.7237\n","Epoch 19/200\n","78/78 [==============================] - 33s 427ms/step - g_loss0: 1.3401 - g_loss1: 1.4036 - g_loss2: 1.2895 - d_loss: 0.8145\n","Epoch 20/200\n","78/78 [==============================] - 34s 433ms/step - g_loss0: 1.1829 - g_loss1: 1.1976 - g_loss2: 1.1357 - d_loss: 0.8154\n","Epoch 21/200\n","78/78 [==============================] - 33s 424ms/step - g_loss0: 1.5752 - g_loss1: 1.3995 - g_loss2: 1.3834 - d_loss: 0.8824\n","Epoch 22/200\n","78/78 [==============================] - 34s 434ms/step - g_loss0: 1.0893 - g_loss1: 1.1199 - g_loss2: 1.1096 - d_loss: 0.8104\n","Epoch 23/200\n","78/78 [==============================] - 34s 439ms/step - g_loss0: 1.1119 - g_loss1: 1.0430 - g_loss2: 0.9771 - d_loss: 0.8771\n","Epoch 24/200\n","78/78 [==============================] - 33s 429ms/step - g_loss0: 1.2669 - g_loss1: 1.1391 - g_loss2: 1.2036 - d_loss: 0.8771\n","Epoch 25/200\n","78/78 [==============================] - 33s 429ms/step - g_loss0: 1.0026 - g_loss1: 1.0798 - g_loss2: 1.0598 - d_loss: 0.8834\n","Epoch 26/200\n","78/78 [==============================] - 33s 429ms/step - g_loss0: 1.1713 - g_loss1: 1.1320 - g_loss2: 1.0370 - d_loss: 0.9176\n","Epoch 27/200\n","78/78 [==============================] - 34s 435ms/step - g_loss0: 1.0856 - g_loss1: 1.0888 - g_loss2: 1.0107 - d_loss: 0.9357\n","Epoch 28/200\n","78/78 [==============================] - 34s 436ms/step - g_loss0: 1.1823 - g_loss1: 1.1207 - g_loss2: 1.0796 - d_loss: 0.9374\n","Epoch 29/200\n","78/78 [==============================] - 33s 429ms/step - g_loss0: 1.1050 - g_loss1: 1.0575 - g_loss2: 1.0462 - d_loss: 0.9341\n","Epoch 30/200\n","78/78 [==============================] - 34s 434ms/step - g_loss0: 1.0595 - g_loss1: 0.9499 - g_loss2: 0.9956 - d_loss: 0.9039\n","Epoch 31/200\n","78/78 [==============================] - 33s 420ms/step - g_loss0: 1.0678 - g_loss1: 0.9892 - g_loss2: 0.9763 - d_loss: 0.9166\n","Epoch 32/200\n","78/78 [==============================] - 33s 429ms/step - g_loss0: 1.0710 - g_loss1: 1.0153 - g_loss2: 0.9661 - d_loss: 0.9357\n","Epoch 33/200\n","78/78 [==============================] - 34s 435ms/step - g_loss0: 1.0243 - g_loss1: 0.9806 - g_loss2: 0.9554 - d_loss: 0.9692\n","Epoch 34/200\n","78/78 [==============================] - 34s 434ms/step - g_loss0: 1.0506 - g_loss1: 1.0369 - g_loss2: 1.0009 - d_loss: 0.9821\n","Epoch 35/200\n","78/78 [==============================] - 34s 432ms/step - g_loss0: 1.0431 - g_loss1: 1.0653 - g_loss2: 1.0355 - d_loss: 0.9681\n","Epoch 36/200\n","78/78 [==============================] - 34s 438ms/step - g_loss0: 1.1068 - g_loss1: 1.0792 - g_loss2: 1.1108 - d_loss: 0.9772\n","Epoch 37/200\n","78/78 [==============================] - 33s 428ms/step - g_loss0: 1.1718 - g_loss1: 1.1430 - g_loss2: 1.1153 - d_loss: 0.9765\n","Epoch 38/200\n","78/78 [==============================] - 34s 434ms/step - g_loss0: 1.0853 - g_loss1: 1.0542 - g_loss2: 1.0533 - d_loss: 0.9584\n","Epoch 39/200\n","78/78 [==============================] - 34s 434ms/step - g_loss0: 1.1154 - g_loss1: 1.0876 - g_loss2: 1.0566 - d_loss: 0.9527\n","Epoch 40/200\n","78/78 [==============================] - 34s 435ms/step - g_loss0: 1.1921 - g_loss1: 1.1514 - g_loss2: 1.1009 - d_loss: 0.9602\n","Epoch 41/200\n","78/78 [==============================] - 33s 429ms/step - g_loss0: 1.1282 - g_loss1: 1.0966 - g_loss2: 1.0777 - d_loss: 0.9192\n","Epoch 42/200\n","78/78 [==============================] - 33s 430ms/step - g_loss0: 1.1605 - g_loss1: 1.1283 - g_loss2: 1.1311 - d_loss: 0.9319\n","Epoch 43/200\n","78/78 [==============================] - 33s 428ms/step - g_loss0: 1.1751 - g_loss1: 1.1200 - g_loss2: 1.1272 - d_loss: 0.9209\n","Epoch 44/200\n","78/78 [==============================] - 34s 433ms/step - g_loss0: 1.2002 - g_loss1: 1.1354 - g_loss2: 1.1438 - d_loss: 0.9300\n","Epoch 45/200\n","78/78 [==============================] - 33s 422ms/step - g_loss0: 1.2016 - g_loss1: 1.1946 - g_loss2: 1.1904 - d_loss: 0.9448\n","Epoch 46/200\n","78/78 [==============================] - 33s 429ms/step - g_loss0: 1.2954 - g_loss1: 1.1773 - g_loss2: 1.1994 - d_loss: 0.9551\n","Epoch 47/200\n","78/78 [==============================] - 33s 429ms/step - g_loss0: 1.2430 - g_loss1: 1.1540 - g_loss2: 1.1235 - d_loss: 0.9387\n","Epoch 48/200\n","78/78 [==============================] - 33s 429ms/step - g_loss0: 1.1870 - g_loss1: 1.1543 - g_loss2: 1.1194 - d_loss: 0.9099\n","Epoch 49/200\n","78/78 [==============================] - 34s 431ms/step - g_loss0: 1.2251 - g_loss1: 1.1713 - g_loss2: 1.1379 - d_loss: 0.9167\n","Epoch 50/200\n","78/78 [==============================] - 33s 429ms/step - g_loss0: 1.2874 - g_loss1: 1.2144 - g_loss2: 1.1675 - d_loss: 0.9262\n","Epoch 51/200\n","78/78 [==============================] - 32s 416ms/step - g_loss0: 1.2424 - g_loss1: 1.2166 - g_loss2: 1.1836 - d_loss: 0.9202\n","Epoch 52/200\n","78/78 [==============================] - 34s 434ms/step - g_loss0: 1.1943 - g_loss1: 1.1337 - g_loss2: 1.1212 - d_loss: 0.8976\n","Epoch 53/200\n","78/78 [==============================] - 34s 434ms/step - g_loss0: 1.2157 - g_loss1: 1.1203 - g_loss2: 1.1072 - d_loss: 0.8969\n","Epoch 54/200\n","78/78 [==============================] - 34s 431ms/step - g_loss0: 1.2440 - g_loss1: 1.1259 - g_loss2: 1.0916 - d_loss: 0.9155\n","Epoch 55/200\n","78/78 [==============================] - 34s 431ms/step - g_loss0: 1.3451 - g_loss1: 1.1674 - g_loss2: 1.1143 - d_loss: 0.9374\n","Epoch 56/200\n","78/78 [==============================] - 34s 430ms/step - g_loss0: 1.3213 - g_loss1: 1.1399 - g_loss2: 1.1024 - d_loss: 0.9425\n","Epoch 57/200\n","78/78 [==============================] - 34s 434ms/step - g_loss0: 1.2198 - g_loss1: 1.0564 - g_loss2: 1.0347 - d_loss: 0.9474\n","Epoch 58/200\n","78/78 [==============================] - 33s 430ms/step - g_loss0: 1.1876 - g_loss1: 1.0433 - g_loss2: 1.0101 - d_loss: 0.9561\n","Epoch 59/200\n","78/78 [==============================] - 34s 435ms/step - g_loss0: 1.2027 - g_loss1: 1.0291 - g_loss2: 1.0220 - d_loss: 0.9585\n","Epoch 60/200\n","78/78 [==============================] - 33s 430ms/step - g_loss0: 1.1456 - g_loss1: 1.0057 - g_loss2: 0.9965 - d_loss: 0.9661\n","Epoch 61/200\n","78/78 [==============================] - 33s 423ms/step - g_loss0: 1.1488 - g_loss1: 0.9820 - g_loss2: 0.9679 - d_loss: 0.9655\n","Epoch 62/200\n","78/78 [==============================] - 33s 430ms/step - g_loss0: 1.1315 - g_loss1: 0.9813 - g_loss2: 0.9550 - d_loss: 0.9759\n","Epoch 63/200\n","78/78 [==============================] - 33s 429ms/step - g_loss0: 1.1308 - g_loss1: 0.9490 - g_loss2: 0.9565 - d_loss: 0.9810\n","Epoch 64/200\n","78/78 [==============================] - 34s 434ms/step - g_loss0: 1.1658 - g_loss1: 0.9521 - g_loss2: 0.9706 - d_loss: 0.9885\n","Epoch 65/200\n","78/78 [==============================] - 34s 434ms/step - g_loss0: 1.4447 - g_loss1: 1.1250 - g_loss2: 1.1001 - d_loss: 1.0482\n","Epoch 66/200\n","78/78 [==============================] - 33s 428ms/step - g_loss0: 1.4340 - g_loss1: 1.1817 - g_loss2: 1.0971 - d_loss: 1.0425\n","Epoch 67/200\n","78/78 [==============================] - 34s 436ms/step - g_loss0: 1.0481 - g_loss1: 0.9221 - g_loss2: 0.9248 - d_loss: 0.9773\n","Epoch 68/200\n","78/78 [==============================] - 33s 429ms/step - g_loss0: 1.1617 - g_loss1: 1.0087 - g_loss2: 0.9765 - d_loss: 1.0039\n","Epoch 69/200\n","78/78 [==============================] - 34s 441ms/step - g_loss0: 1.1895 - g_loss1: 1.0555 - g_loss2: 1.0374 - d_loss: 1.0077\n","Epoch 70/200\n","78/78 [==============================] - 34s 433ms/step - g_loss0: 1.0870 - g_loss1: 0.9674 - g_loss2: 0.9656 - d_loss: 0.9906\n","Epoch 71/200\n","78/78 [==============================] - 36s 456ms/step - g_loss0: 1.0616 - g_loss1: 0.9432 - g_loss2: 0.9482 - d_loss: 0.9919\n","Epoch 72/200\n","78/78 [==============================] - 34s 431ms/step - g_loss0: 1.0321 - g_loss1: 0.9285 - g_loss2: 0.9392 - d_loss: 0.9955\n","Epoch 73/200\n","78/78 [==============================] - 34s 436ms/step - g_loss0: 1.0270 - g_loss1: 0.9228 - g_loss2: 0.9227 - d_loss: 1.0017\n","Epoch 74/200\n","78/78 [==============================] - 33s 430ms/step - g_loss0: 1.0359 - g_loss1: 0.9239 - g_loss2: 0.9345 - d_loss: 1.0080\n","Epoch 75/200\n","78/78 [==============================] - 34s 435ms/step - g_loss0: 1.0411 - g_loss1: 0.9225 - g_loss2: 0.9341 - d_loss: 1.0025\n","Epoch 76/200\n","78/78 [==============================] - 34s 436ms/step - g_loss0: 1.0943 - g_loss1: 0.9570 - g_loss2: 0.9718 - d_loss: 1.0203\n","Epoch 77/200\n","78/78 [==============================] - 34s 431ms/step - g_loss0: 1.1748 - g_loss1: 1.0264 - g_loss2: 1.0096 - d_loss: 1.0260\n","Epoch 78/200\n","78/78 [==============================] - 34s 436ms/step - g_loss0: 1.8596 - g_loss1: 1.4625 - g_loss2: 1.3217 - d_loss: 1.2145\n","Epoch 79/200\n","78/78 [==============================] - 34s 432ms/step - g_loss0: 0.9710 - g_loss1: 0.9052 - g_loss2: 0.9031 - d_loss: 0.9806\n","Epoch 80/200\n","78/78 [==============================] - 34s 431ms/step - g_loss0: 0.9939 - g_loss1: 0.8915 - g_loss2: 0.8954 - d_loss: 0.9751\n","Epoch 81/200\n","78/78 [==============================] - 33s 418ms/step - g_loss0: 0.9795 - g_loss1: 0.8841 - g_loss2: 0.8898 - d_loss: 0.9861\n","Epoch 82/200\n","78/78 [==============================] - 34s 435ms/step - g_loss0: 1.0029 - g_loss1: 0.9190 - g_loss2: 0.9240 - d_loss: 0.9953\n","Epoch 83/200\n","78/78 [==============================] - 34s 430ms/step - g_loss0: 1.1482 - g_loss1: 1.0382 - g_loss2: 1.0185 - d_loss: 1.0231\n","Epoch 84/200\n","78/78 [==============================] - 34s 439ms/step - g_loss0: 1.0539 - g_loss1: 0.9638 - g_loss2: 0.9570 - d_loss: 1.0089\n","Epoch 85/200\n","78/78 [==============================] - 34s 433ms/step - g_loss0: 1.0209 - g_loss1: 0.9294 - g_loss2: 0.9245 - d_loss: 0.9955\n","Epoch 86/200\n","78/78 [==============================] - 34s 431ms/step - g_loss0: 1.0524 - g_loss1: 0.9568 - g_loss2: 0.9465 - d_loss: 1.0075\n","Epoch 87/200\n","78/78 [==============================] - 34s 437ms/step - g_loss0: 1.0079 - g_loss1: 0.9251 - g_loss2: 0.9170 - d_loss: 1.0079\n","Epoch 88/200\n","78/78 [==============================] - 34s 432ms/step - g_loss0: 1.0176 - g_loss1: 0.9278 - g_loss2: 0.9239 - d_loss: 1.0027\n","Epoch 89/200\n","78/78 [==============================] - 34s 432ms/step - g_loss0: 1.0100 - g_loss1: 0.9417 - g_loss2: 0.9292 - d_loss: 1.0057\n","Epoch 90/200\n","78/78 [==============================] - 34s 436ms/step - g_loss0: 0.9993 - g_loss1: 0.9114 - g_loss2: 0.9108 - d_loss: 1.0065\n","Epoch 91/200\n","78/78 [==============================] - 33s 418ms/step - g_loss0: 0.9975 - g_loss1: 0.9156 - g_loss2: 0.8928 - d_loss: 1.0060\n","Epoch 92/200\n","78/78 [==============================] - 33s 430ms/step - g_loss0: 1.0145 - g_loss1: 0.9167 - g_loss2: 0.8993 - d_loss: 1.0082\n","Epoch 93/200\n","78/78 [==============================] - 34s 432ms/step - g_loss0: 0.9988 - g_loss1: 0.9214 - g_loss2: 0.9048 - d_loss: 1.0082\n","Epoch 94/200\n","78/78 [==============================] - 34s 436ms/step - g_loss0: 1.0181 - g_loss1: 0.9323 - g_loss2: 0.9210 - d_loss: 1.0027\n","Epoch 95/200\n","78/78 [==============================] - 33s 428ms/step - g_loss0: 1.0381 - g_loss1: 0.9519 - g_loss2: 0.9388 - d_loss: 1.0155\n","Epoch 96/200\n","78/78 [==============================] - 34s 433ms/step - g_loss0: 1.7082 - g_loss1: 1.4153 - g_loss2: 1.2463 - d_loss: 1.1241\n","Epoch 97/200\n","78/78 [==============================] - 34s 432ms/step - g_loss0: 1.2531 - g_loss1: 1.1327 - g_loss2: 1.0735 - d_loss: 1.1265\n","Epoch 98/200\n","78/78 [==============================] - 34s 431ms/step - g_loss0: 0.9534 - g_loss1: 0.9007 - g_loss2: 0.8762 - d_loss: 0.9787\n","Epoch 99/200\n","78/78 [==============================] - 34s 432ms/step - g_loss0: 0.9820 - g_loss1: 0.9161 - g_loss2: 0.8862 - d_loss: 0.9962\n","Epoch 100/200\n","78/78 [==============================] - 33s 425ms/step - g_loss0: 0.9972 - g_loss1: 0.9277 - g_loss2: 0.9054 - d_loss: 0.9953\n","Epoch 101/200\n","78/78 [==============================] - 33s 422ms/step - g_loss0: 1.0102 - g_loss1: 0.9548 - g_loss2: 0.9365 - d_loss: 0.9980\n","Epoch 102/200\n","78/78 [==============================] - 34s 434ms/step - g_loss0: 1.0364 - g_loss1: 0.9661 - g_loss2: 0.9598 - d_loss: 1.0118\n","Epoch 103/200\n","78/78 [==============================] - 34s 436ms/step - g_loss0: 0.9986 - g_loss1: 0.9291 - g_loss2: 0.9013 - d_loss: 0.9867\n","Epoch 104/200\n","78/78 [==============================] - 34s 432ms/step - g_loss0: 1.0129 - g_loss1: 0.9407 - g_loss2: 0.9194 - d_loss: 0.9991\n","Epoch 105/200\n","78/78 [==============================] - 34s 437ms/step - g_loss0: 1.0150 - g_loss1: 0.9545 - g_loss2: 0.9269 - d_loss: 0.9907\n","Epoch 106/200\n","78/78 [==============================] - 33s 430ms/step - g_loss0: 1.0381 - g_loss1: 0.9693 - g_loss2: 0.9396 - d_loss: 1.0027\n","Epoch 107/200\n","78/78 [==============================] - 34s 433ms/step - g_loss0: 1.0259 - g_loss1: 0.9619 - g_loss2: 0.9297 - d_loss: 1.0021\n","Epoch 108/200\n","78/78 [==============================] - 34s 437ms/step - g_loss0: 0.9794 - g_loss1: 0.9245 - g_loss2: 0.9023 - d_loss: 0.9916\n","Epoch 109/200\n","78/78 [==============================] - 34s 431ms/step - g_loss0: 0.9733 - g_loss1: 0.9138 - g_loss2: 0.9015 - d_loss: 0.9841\n","Epoch 110/200\n","78/78 [==============================] - 34s 436ms/step - g_loss0: 0.9738 - g_loss1: 0.9201 - g_loss2: 0.9038 - d_loss: 0.9872\n","Epoch 111/200\n","78/78 [==============================] - 33s 419ms/step - g_loss0: 1.0354 - g_loss1: 0.9990 - g_loss2: 0.9634 - d_loss: 0.9970\n","Epoch 112/200\n","78/78 [==============================] - 34s 442ms/step - g_loss0: 0.9895 - g_loss1: 0.9322 - g_loss2: 0.9141 - d_loss: 0.9946\n","Epoch 113/200\n","78/78 [==============================] - 34s 437ms/step - g_loss0: 1.0283 - g_loss1: 0.9714 - g_loss2: 0.9385 - d_loss: 0.9903\n","Epoch 114/200\n","78/78 [==============================] - 34s 436ms/step - g_loss0: 0.9946 - g_loss1: 0.9430 - g_loss2: 0.9229 - d_loss: 0.9840\n","Epoch 115/200\n","78/78 [==============================] - 34s 436ms/step - g_loss0: 0.9968 - g_loss1: 0.9549 - g_loss2: 0.9216 - d_loss: 0.9856\n","Epoch 116/200\n","78/78 [==============================] - 34s 430ms/step - g_loss0: 1.0182 - g_loss1: 0.9731 - g_loss2: 0.9359 - d_loss: 0.9790\n","Epoch 117/200\n","78/78 [==============================] - 34s 435ms/step - g_loss0: 1.0184 - g_loss1: 0.9726 - g_loss2: 0.9425 - d_loss: 0.9919\n","Epoch 118/200\n","78/78 [==============================] - 33s 430ms/step - g_loss0: 1.0334 - g_loss1: 1.0008 - g_loss2: 0.9625 - d_loss: 0.9801\n","Epoch 119/200\n","78/78 [==============================] - 34s 431ms/step - g_loss0: 1.0264 - g_loss1: 0.9822 - g_loss2: 0.9528 - d_loss: 0.9873\n","Epoch 120/200\n","78/78 [==============================] - 34s 435ms/step - g_loss0: 1.0190 - g_loss1: 0.9646 - g_loss2: 0.9327 - d_loss: 0.9774\n","Epoch 121/200\n","78/78 [==============================] - 33s 423ms/step - g_loss0: 1.0508 - g_loss1: 0.9967 - g_loss2: 0.9592 - d_loss: 0.9852\n","Epoch 122/200\n","78/78 [==============================] - 33s 429ms/step - g_loss0: 1.0035 - g_loss1: 0.9659 - g_loss2: 0.9362 - d_loss: 0.9765\n","Epoch 123/200\n","78/78 [==============================] - 34s 436ms/step - g_loss0: 1.0115 - g_loss1: 0.9764 - g_loss2: 0.9354 - d_loss: 0.9749\n","Epoch 124/200\n","78/78 [==============================] - 34s 435ms/step - g_loss0: 0.9930 - g_loss1: 0.9550 - g_loss2: 0.9249 - d_loss: 0.9680\n","Epoch 125/200\n","78/78 [==============================] - 33s 430ms/step - g_loss0: 1.0461 - g_loss1: 0.9986 - g_loss2: 0.9561 - d_loss: 0.9771\n","Epoch 126/200\n","78/78 [==============================] - 34s 432ms/step - g_loss0: 1.0582 - g_loss1: 1.0285 - g_loss2: 0.9826 - d_loss: 0.9748\n","Epoch 127/200\n","78/78 [==============================] - 34s 432ms/step - g_loss0: 1.0264 - g_loss1: 0.9859 - g_loss2: 0.9458 - d_loss: 0.9702\n","Epoch 128/200\n","78/78 [==============================] - 34s 431ms/step - g_loss0: 1.0218 - g_loss1: 0.9701 - g_loss2: 0.9389 - d_loss: 0.9651\n","Epoch 129/200\n","78/78 [==============================] - 34s 432ms/step - g_loss0: 0.9954 - g_loss1: 0.9512 - g_loss2: 0.9177 - d_loss: 0.9625\n","Epoch 130/200\n","78/78 [==============================] - 34s 436ms/step - g_loss0: 1.0017 - g_loss1: 0.9497 - g_loss2: 0.9227 - d_loss: 0.9647\n","Epoch 131/200\n","78/78 [==============================] - 33s 423ms/step - g_loss0: 1.0370 - g_loss1: 0.9839 - g_loss2: 0.9523 - d_loss: 0.9651\n","Epoch 132/200\n","78/78 [==============================] - 33s 429ms/step - g_loss0: 1.0997 - g_loss1: 1.0498 - g_loss2: 1.0042 - d_loss: 0.9728\n","Epoch 133/200\n","78/78 [==============================] - 34s 435ms/step - g_loss0: 1.0220 - g_loss1: 0.9783 - g_loss2: 0.9453 - d_loss: 0.9646\n","Epoch 134/200\n","78/78 [==============================] - 34s 434ms/step - g_loss0: 1.0206 - g_loss1: 0.9749 - g_loss2: 0.9365 - d_loss: 0.9570\n","Epoch 135/200\n","78/78 [==============================] - 34s 436ms/step - g_loss0: 1.0313 - g_loss1: 0.9837 - g_loss2: 0.9451 - d_loss: 0.9563\n","Epoch 136/200\n","78/78 [==============================] - 34s 436ms/step - g_loss0: 1.0249 - g_loss1: 0.9790 - g_loss2: 0.9436 - d_loss: 0.9536\n","Epoch 137/200\n","78/78 [==============================] - 34s 431ms/step - g_loss0: 1.0368 - g_loss1: 0.9916 - g_loss2: 0.9525 - d_loss: 0.9526\n","Epoch 138/200\n","78/78 [==============================] - 34s 440ms/step - g_loss0: 1.0564 - g_loss1: 1.0056 - g_loss2: 0.9597 - d_loss: 0.9519\n","Epoch 139/200\n","78/78 [==============================] - 34s 442ms/step - g_loss0: 1.1241 - g_loss1: 1.0736 - g_loss2: 1.0165 - d_loss: 0.9611\n","Epoch 140/200\n","78/78 [==============================] - 34s 438ms/step - g_loss0: 1.1436 - g_loss1: 1.0964 - g_loss2: 1.0278 - d_loss: 0.9630\n","Epoch 141/200\n","78/78 [==============================] - 33s 430ms/step - g_loss0: 1.1048 - g_loss1: 1.0571 - g_loss2: 1.0043 - d_loss: 0.9635\n","Epoch 142/200\n","78/78 [==============================] - 34s 435ms/step - g_loss0: 1.0490 - g_loss1: 1.0072 - g_loss2: 0.9640 - d_loss: 0.9421\n","Epoch 143/200\n","78/78 [==============================] - 34s 437ms/step - g_loss0: 1.0254 - g_loss1: 0.9753 - g_loss2: 0.9283 - d_loss: 0.9367\n","Epoch 144/200\n","78/78 [==============================] - 34s 436ms/step - g_loss0: 1.0372 - g_loss1: 0.9942 - g_loss2: 0.9530 - d_loss: 0.9370\n","Epoch 145/200\n","78/78 [==============================] - 39s 498ms/step - g_loss0: 1.0498 - g_loss1: 1.0086 - g_loss2: 0.9644 - d_loss: 0.9433\n","Epoch 146/200\n","78/78 [==============================] - 34s 440ms/step - g_loss0: 1.1714 - g_loss1: 1.1232 - g_loss2: 1.0401 - d_loss: 0.9610\n","Epoch 147/200\n","78/78 [==============================] - 34s 435ms/step - g_loss0: 1.0968 - g_loss1: 1.0500 - g_loss2: 0.9935 - d_loss: 0.9402\n","Epoch 148/200\n","78/78 [==============================] - 34s 440ms/step - g_loss0: 1.0520 - g_loss1: 1.0031 - g_loss2: 0.9641 - d_loss: 0.9254\n","Epoch 149/200\n","78/78 [==============================] - 34s 435ms/step - g_loss0: 1.0576 - g_loss1: 1.0104 - g_loss2: 0.9676 - d_loss: 0.9343\n","Epoch 150/200\n","78/78 [==============================] - 34s 438ms/step - g_loss0: 1.0648 - g_loss1: 1.0194 - g_loss2: 0.9658 - d_loss: 0.9322\n","Epoch 151/200\n","78/78 [==============================] - 33s 428ms/step - g_loss0: 1.0404 - g_loss1: 0.9961 - g_loss2: 0.9444 - d_loss: 0.9303\n","Epoch 152/200\n","78/78 [==============================] - 35s 446ms/step - g_loss0: 1.0319 - g_loss1: 0.9899 - g_loss2: 0.9453 - d_loss: 0.9198\n","Epoch 153/200\n","78/78 [==============================] - 34s 437ms/step - g_loss0: 1.0478 - g_loss1: 1.0016 - g_loss2: 0.9542 - d_loss: 0.9299\n","Epoch 154/200\n","78/78 [==============================] - 35s 443ms/step - g_loss0: 1.0815 - g_loss1: 1.0328 - g_loss2: 0.9731 - d_loss: 0.9370\n","Epoch 155/200\n","78/78 [==============================] - 34s 437ms/step - g_loss0: 1.1636 - g_loss1: 1.1018 - g_loss2: 1.0221 - d_loss: 0.9369\n","Epoch 156/200\n","78/78 [==============================] - 35s 445ms/step - g_loss0: 1.0683 - g_loss1: 1.0146 - g_loss2: 0.9642 - d_loss: 0.9213\n","Epoch 157/200\n","78/78 [==============================] - 34s 440ms/step - g_loss0: 1.0408 - g_loss1: 0.9964 - g_loss2: 0.9442 - d_loss: 0.9158\n","Epoch 158/200\n","78/78 [==============================] - 34s 443ms/step - g_loss0: 1.0467 - g_loss1: 1.0043 - g_loss2: 0.9515 - d_loss: 0.9213\n","Epoch 159/200\n","78/78 [==============================] - 34s 432ms/step - g_loss0: 1.1064 - g_loss1: 1.0611 - g_loss2: 0.9968 - d_loss: 0.9296\n","Epoch 160/200\n","78/78 [==============================] - 34s 435ms/step - g_loss0: 1.1226 - g_loss1: 1.0746 - g_loss2: 1.0135 - d_loss: 0.9245\n","Epoch 161/200\n","78/78 [==============================] - 33s 424ms/step - g_loss0: 1.0946 - g_loss1: 1.0565 - g_loss2: 1.0052 - d_loss: 0.9263\n","Epoch 162/200\n","78/78 [==============================] - 34s 435ms/step - g_loss0: 1.0927 - g_loss1: 1.0618 - g_loss2: 0.9908 - d_loss: 0.9200\n","Epoch 163/200\n","78/78 [==============================] - 34s 431ms/step - g_loss0: 1.0829 - g_loss1: 1.0394 - g_loss2: 0.9858 - d_loss: 0.9201\n","Epoch 164/200\n","78/78 [==============================] - 34s 441ms/step - g_loss0: 1.0733 - g_loss1: 1.0361 - g_loss2: 0.9796 - d_loss: 0.9171\n","Epoch 165/200\n","78/78 [==============================] - 34s 432ms/step - g_loss0: 1.0843 - g_loss1: 1.0361 - g_loss2: 0.9711 - d_loss: 0.9113\n","Epoch 166/200\n","78/78 [==============================] - 34s 432ms/step - g_loss0: 1.0788 - g_loss1: 1.0421 - g_loss2: 0.9879 - d_loss: 0.9198\n","Epoch 167/200\n","78/78 [==============================] - 34s 437ms/step - g_loss0: 1.0659 - g_loss1: 1.0210 - g_loss2: 0.9669 - d_loss: 0.9099\n","Epoch 168/200\n","78/78 [==============================] - 34s 431ms/step - g_loss0: 1.0817 - g_loss1: 1.0484 - g_loss2: 0.9821 - d_loss: 0.9139\n","Epoch 169/200\n","78/78 [==============================] - 34s 436ms/step - g_loss0: 1.1768 - g_loss1: 1.1252 - g_loss2: 1.0373 - d_loss: 0.9342\n","Epoch 170/200\n","78/78 [==============================] - 34s 437ms/step - g_loss0: 1.0829 - g_loss1: 1.0411 - g_loss2: 0.9773 - d_loss: 0.9027\n","Epoch 171/200\n","78/78 [==============================] - 34s 430ms/step - g_loss0: 1.0750 - g_loss1: 1.0304 - g_loss2: 0.9702 - d_loss: 0.8990\n","Epoch 172/200\n","78/78 [==============================] - 34s 431ms/step - g_loss0: 1.0644 - g_loss1: 1.0284 - g_loss2: 0.9639 - d_loss: 0.8966\n","Epoch 173/200\n","78/78 [==============================] - 33s 430ms/step - g_loss0: 1.1027 - g_loss1: 1.0596 - g_loss2: 0.9908 - d_loss: 0.9106\n","Epoch 174/200\n","22/78 [=======>......................] - ETA: 25s - g_loss0: 1.1273 - g_loss1: 1.0716 - g_loss2: 1.0041 - d_loss: 0.9134"]}]},{"cell_type":"markdown","metadata":{"id":"4FDNnzt1qxmJ"},"source":["# Saving GIF file"]},{"cell_type":"code","metadata":{"id":"x3AdDZAsoX6S","executionInfo":{"status":"ok","timestamp":1632608790307,"user_tz":-210,"elapsed":96007,"user":{"displayName":"Alireza Daeijavad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09426646207156988252"}}},"source":["anim_file = 'madgan2.gif'\n","\n","with imageio.get_writer(f'/content/drive/MyDrive/{dir_name}/{anim_file}', mode='I') as writer:\n","    filenames = glob.glob(f'/content/drive/MyDrive/{dir_name}/Pictures/image_at_epoch_*.png')\n","    filenames = sorted(filenames)\n","    for filename in filenames:\n","        image = imageio.imread(filename)\n","        # image = image[::2,::2,:]\n","        writer.append_data(image)\n","    for i in range(20):\n","        writer.append_data(image)   \n","\n","# Reduce GIF size\n","optimize(f'/content/drive/MyDrive/{dir_name}/{anim_file}')"],"execution_count":7,"outputs":[]}]}